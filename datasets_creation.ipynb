{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install patool\n",
    "import patoolib\n",
    "patoolib.extract_archive(\"train-resized.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 2 | val:  2\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def move_files(source_folder, files, destination_folder):\n",
    "    for file_name in files:\n",
    "        source_path = os.path.join(source_folder, file_name)\n",
    "        destination_path = os.path.join(destination_folder, file_name)\n",
    "        shutil.move(source_path, destination_path)\n",
    "\n",
    "def create_validation_set(train_folder, validation_folder, train_csv, split_ratio=0.2):\n",
    "    # Create the validation folder if it doesn't exist\n",
    "    if not os.path.exists(validation_folder):\n",
    "        os.makedirs(validation_folder)\n",
    "\n",
    "    # List all files in the source folder\n",
    "    files = os.listdir(train_folder)\n",
    "\n",
    "    # Calculate the number of files to move to the validation set\n",
    "    num_files = len(files)\n",
    "    num_validation_files = int(num_files * split_ratio)\n",
    "\n",
    "    # Select the first portion of files for the validation set\n",
    "    validation_files = files[:num_validation_files]\n",
    "\n",
    "    train_csv = os.path.join(data_root_path, train_csv)\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(train_csv)\n",
    "    df.sort_values([\"image_name\"], inplace=True)\n",
    "    # Create a new DataFrame with the first num_validation_files rows\n",
    "    validation_df = df.iloc[:num_validation_files]\n",
    "    # Save the validation DataFrame to a new CSV file\n",
    "    validation_csv_file = os.path.join(data_root_path, \"validation-labels.csv\")\n",
    "    validation_df.to_csv(validation_csv_file, index=False)\n",
    "    # Remove the first num_validation_files rows from the original DataFrame\n",
    "    df = df.iloc[num_validation_files:]\n",
    "    # Save the modified DataFrame back to the original CSV file\n",
    "    df.to_csv(train_csv, index=False)\n",
    "\n",
    "    move_files(train_folder, validation_files, validation_folder)\n",
    "\n",
    "# RUN ONLY ONCE !\n",
    "data_root_path = \".\"\n",
    "train_path = os.path.join(data_root_path, \"train\")\n",
    "validation_path = os.path.join(data_root_path, \"validation\")\n",
    "create_validation_set(train_path, validation_path, \"train-labels.csv\")\n",
    "print(\"train:\", len(os.listdir(train_path)), \"| val: \", len(os.listdir(validation_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ ONLY RUN TO REVERT PREVIOUS OPERATION ###################################\n",
    "# Revert validation set creation if you made a mistake (empties validation folder and puts the files\n",
    "# back to training folder and modifies the csv accordingly)\n",
    "files = os.listdir(\"validation\")\n",
    "move_files(\"validation\", files, \"train\")\n",
    "print(\"train:\", len(os.listdir(\"train\")), \"| val: \", len(os.listdir(\"validation\")))\n",
    "\n",
    "validation_csv = \"validation-labels.csv\"\n",
    "train_csv = \"train-labels.csv\"\n",
    "validation_df = pd.read_csv(validation_csv)\n",
    "train_df = pd.read_csv(train_csv)\n",
    "restored_train_df = pd.concat([validation_df, train_df], ignore_index=True)\n",
    "restored_train_df.to_csv(train_csv, index=False)\n",
    "os.remove(validation_csv)\n",
    "print(len(restored_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def create_class_folders(image_folder, csv_file):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file, header=0, names=['Image', 'Class'])\n",
    "\n",
    "    # Create two class folders within the \"train\" directory\n",
    "    class0_folder = os.path.join(image_folder, 'class0')\n",
    "    class1_folder = os.path.join(image_folder, 'class1')\n",
    "\n",
    "    os.makedirs(class0_folder)\n",
    "    os.makedirs(class1_folder)\n",
    "\n",
    "    # Move images to their respective class folders\n",
    "    for index, row in df.iterrows():\n",
    "        image_name = row['Image'] + '.jpg'  # Assuming image files have the '.jpg' extension\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        \n",
    "        if row['Class'] == 0:\n",
    "            destination_folder = class0_folder\n",
    "        elif row['Class'] == 1:\n",
    "            destination_folder = class1_folder\n",
    "        else:\n",
    "            print(f\"Skipping invalid class label for image {image_name}\")\n",
    "            continue\n",
    "\n",
    "        # Move the image to the destination folder\n",
    "        shutil.move(image_path, os.path.join(destination_folder, image_name))\n",
    "\n",
    "train_csv = os.path.join(data_root_path, \"train-labels.csv\")\n",
    "validation_csv = os.path.join(data_root_path, \"validation-labels.csv\")\n",
    "create_class_folders(train_path, train_csv)\n",
    "create_class_folders(validation_path, validation_csv)\n",
    "print(\"Images have been organized into class folders.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
